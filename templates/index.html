<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Self-Hosted Search</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}" />
  </head>
  <body data-smart-min-results="{{ smart_min_results }}">
    <main class="container">
      <h1>Self-Hosted Search</h1>
      <div class="layout">
        <section class="search-panel" aria-label="Search panel">
          <form id="search-form" role="search" aria-label="Search local index">
            <label class="sr-only" for="query-input">Search query</label>
            <input
              id="query-input"
              name="q"
              type="search"
              placeholder="Search your index..."
              value="{{ query|default('') }}"
              autocomplete="off"
              required
            />
            <button type="submit">Search</button>
          </form>
          <label class="toggle">
            <input type="checkbox" id="llm-toggle" />
            <span>Use LLM for discovery (focused crawl)</span>
          </label>
          <section
            id="embedder-status"
            class="embedder-status"
            aria-live="polite"
            aria-busy="false"
          >
            <div class="embedder-header">
              <h2>Embedding model</h2>
              <p id="embedder-status-text">Checking Ollama…</p>
            </div>
            <div
              id="embedder-progress"
              class="embedder-progress"
              role="progressbar"
              aria-valuemin="0"
              aria-valuemax="100"
              aria-valuenow="0"
              hidden
            >
              <div id="embedder-progress-bar"></div>
            </div>
            <div class="embedder-actions">
              <button type="button" id="embedder-retry" hidden>Retry</button>
              <div id="embedder-fallback-group" class="fallback-group" hidden>
                <label for="embedder-fallback-select">Use fallback</label>
                <select id="embedder-fallback-select"></select>
                <button type="button" id="embedder-fallback-apply">Apply</button>
              </div>
              <button type="button" id="embedder-start" hidden>Start Ollama</button>
            </div>
            <p class="embedder-help" id="embedder-help-text">
              We'll install <code>embeddinggemma</code> automatically. Manual command:
              <code>ollama pull embeddinggemma</code>
            </p>
          </section>
          <section id="status" aria-live="polite" aria-busy="false"></section>
          <section id="focused-status" class="focused-status" aria-live="polite" aria-busy="false" hidden>
            <h2>Focused crawl activity</h2>
            <p id="focused-message">Searching deeper…</p>
            <pre id="focused-log" aria-label="Focused crawl log tail"></pre>
          </section>
          <section id="results" aria-live="polite"></section>
        </section>
        <aside class="assist-panel" aria-label="AI Assist">
          <div class="assist-header">
            <h2>AI Assist</h2>
            <p id="llm-status-text" class="llm-status">Checking Ollama...</p>
            <div class="field">
              <label for="llm-model">Model</label>
              <select id="llm-model" disabled>
                <option value="">Detecting models...</option>
              </select>
            </div>
          </div>
          <div class="assist-tabs" role="tablist">
            <button
              type="button"
              class="assist-tab active"
              id="chat-tab"
              data-tab="chat"
              role="tab"
              aria-controls="chat-panel"
              aria-selected="true"
            >
              Chat
            </button>
            <button
              type="button"
              class="assist-tab"
              id="research-tab"
              data-tab="research"
              role="tab"
              aria-controls="research-panel"
              aria-selected="false"
            >
              Deep Research
            </button>
          </div>
          <section id="chat-panel" class="tab-panel active" role="tabpanel" aria-labelledby="chat-tab">
            <div id="chat-messages" class="chat-messages" aria-live="polite"></div>
            <form id="chat-form" class="chat-form">
              <label class="sr-only" for="chat-input">Ask the assistant</label>
              <textarea id="chat-input" rows="3" placeholder="Ask the local model…" required></textarea>
              <div class="chat-actions">
                <button type="submit" id="chat-send">Send</button>
              </div>
            </form>
          </section>
          <section
            id="research-panel"
            class="tab-panel"
            role="tabpanel"
            aria-labelledby="research-tab"
            hidden
          >
            <form id="research-form" class="research-form">
              <label for="research-query">Research question</label>
              <textarea
                id="research-query"
                rows="4"
                placeholder="What would you like to investigate?"
                required
              ></textarea>
              <div class="field-group">
                <label for="research-budget">Crawl budget</label>
                <input id="research-budget" type="number" min="1" max="100" value="20" />
              </div>
              <button type="submit" id="research-start">Start research</button>
            </form>
            <section class="research-status" aria-live="polite">
              <h3>Job activity</h3>
              <pre id="research-log"></pre>
            </section>
            <article id="research-report" class="research-report" hidden>
              <header>
                <h3>Research report</h3>
                <a id="research-report-download" href="#" download>Save to file</a>
              </header>
              <div id="research-report-content"></div>
            </article>
          </section>
          <div id="llm-instructions" class="llm-instructions" hidden>
            <p id="llm-instructions-text">Ollama is not ready. Install and run it locally to enable AI-assisted discovery:</p>
            <p><strong>macOS:</strong></p>
            <pre><code>brew install --cask ollama
ollama serve
ollama pull llama3.1:8b-instruct</code></pre>
            <p>
              See the
              <a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">official Ollama documentation</a>
              for more details.
            </p>
          </div>
          <section class="cheat-sheet" aria-label="Fielded search tips">
            <h3>Fielded search tips</h3>
            <ul>
              <li><code>title:"python packaging"</code> — boost matches in page titles.</li>
              <li><code>h1h2:guide</code> — focus on headings and subheadings.</li>
              <li><code>lang:en packaging tutorial</code> — filter by detected language.</li>
            </ul>
          </section>
        </aside>
      </div>
    </main>
    
<script>
  const form = document.getElementById("search-form");
  const queryInput = document.getElementById("query-input");
  const statusEl = document.getElementById("status");
  const resultsEl = document.getElementById("results");
  const focusedSection = document.getElementById("focused-status");
  const focusedMessage = document.getElementById("focused-message");
  const focusedLog = document.getElementById("focused-log");
  const llmStatusEl = document.getElementById("llm-status-text");
  const llmModelSelect = document.getElementById("llm-model");
  const llmToggle = document.getElementById("llm-toggle");
  const llmInstructions = document.getElementById("llm-instructions");
  const llmInstructionsText = document.getElementById("llm-instructions-text");
  const defaultInstructionsText = llmInstructionsText ? llmInstructionsText.textContent : "";
  const embedderContainer = document.getElementById("embedder-status");
  const embedderStatusText = document.getElementById("embedder-status-text");
  const embedderProgress = document.getElementById("embedder-progress");
  const embedderProgressBar = document.getElementById("embedder-progress-bar");
  const embedderRetryBtn = document.getElementById("embedder-retry");
  const embedderFallbackGroup = document.getElementById("embedder-fallback-group");
  const embedderFallbackSelect = document.getElementById("embedder-fallback-select");
  const embedderFallbackApply = document.getElementById("embedder-fallback-apply");
  const embedderStartBtn = document.getElementById("embedder-start");
  const embedderHelpText = document.getElementById("embedder-help-text");
  const chatTabs = document.querySelectorAll(".assist-tab");
  const chatPanel = document.getElementById("chat-panel");
  const researchPanel = document.getElementById("research-panel");
  const chatMessagesEl = document.getElementById("chat-messages");
  const chatForm = document.getElementById("chat-form");
  const chatInput = document.getElementById("chat-input");
  const chatSend = document.getElementById("chat-send");
  const researchForm = document.getElementById("research-form");
  const researchQuery = document.getElementById("research-query");
  const researchBudget = document.getElementById("research-budget");
  const researchLog = document.getElementById("research-log");
  const researchReport = document.getElementById("research-report");
  const researchReportContent = document.getElementById("research-report-content");
  const researchReportDownload = document.getElementById("research-report-download");

  const SMART_MIN_RESULTS = Number(document.body.dataset.smartMinResults || "1");
  const STORAGE_MODEL_KEY = "ollama_model";
  const STORAGE_TOGGLE_KEY = "smart_use_llm";
  const EMBEDDING_MODEL_PATTERNS = [
    /(?:^|[-_:])embed(?:ding)?/i,
    /(?:^|[-_:])gte[-_:]/i,
    /(?:^|[-_:])bge[-_:]/i,
    /(?:^|[-_:])text2vec/i,
    /(?:^|[-_:])e5[-_:]/i,
  ];

  const state = {
    searchJobId: null,
    searchJobTimer: null,
    indexTimer: null,
    baselineIndexTime: 0,
    latestIndexTime: 0,
    autoRefresh: false,
    lastQuery: queryInput.value.trim(),
    lastParams: "",
    chatMessages: [],
    researchJobId: null,
    researchPollTimer: null,
    embedder: {
      status: null,
      pollTimer: null,
      pendingSearch: null,
    },
  };

  function isEmbeddingModelName(name) {
    if (!name || typeof name !== "string") {
      return false;
    }
    return EMBEDDING_MODEL_PATTERNS.some((pattern) => pattern.test(name));
  }

  function filterChatCapableModels(models) {
    if (!Array.isArray(models)) {
      return [];
    }
    return models
      .map((model) => {
        if (typeof model === "string") {
          const trimmed = model.trim();
          return trimmed ? { name: trimmed } : null;
        }
        if (model && typeof model.name === "string") {
          const trimmed = model.name.trim();
          if (!trimmed) {
            return null;
          }
          return { ...model, name: trimmed };
        }
        return null;
      })
      .filter((model) => model && model.name && !isEmbeddingModelName(model.name));
  }

  function setTab(tabId) {
    const panels = { chat: chatPanel, research: researchPanel };
    chatTabs.forEach((button) => {
      const active = button.dataset.tab === tabId;
      button.classList.toggle("active", active);
      button.setAttribute("aria-selected", active ? "true" : "false");
      const panel = panels[button.dataset.tab];
      if (panel) {
        panel.classList.toggle("active", active);
        panel.hidden = !active;
      }
    });
  }

  chatTabs.forEach((button) => {
    button.addEventListener("click", () => setTab(button.dataset.tab));
  });

  const savedToggle = localStorage.getItem(STORAGE_TOGGLE_KEY);
  if (savedToggle !== null) {
    llmToggle.checked = savedToggle === "true";
  }

  llmToggle.addEventListener("change", () => {
    localStorage.setItem(STORAGE_TOGGLE_KEY, String(llmToggle.checked));
  });

  llmModelSelect.addEventListener("change", () => {
    localStorage.setItem(STORAGE_MODEL_KEY, llmModelSelect.value);
  });

  if (embedderRetryBtn) {
    embedderRetryBtn.addEventListener("click", () => {
      refreshEmbedderStatus({ triggerInstall: true });
    });
  }

  if (embedderStartBtn) {
    embedderStartBtn.addEventListener("click", () => {
      refreshEmbedderStatus({ triggerInstall: true });
    });
  }

  if (embedderFallbackApply) {
    embedderFallbackApply.addEventListener("click", () => {
      if (!embedderFallbackSelect) {
        return;
      }
      const selection = embedderFallbackSelect.value;
      if (!selection) {
        return;
      }
      refreshEmbedderStatus({ triggerInstall: true, model: selection });
    });
  }

  function updateStatus(text, busy = false) {
    statusEl.textContent = text;
    statusEl.setAttribute("aria-busy", busy ? "true" : "false");
  }

  function populateFallbackOptions(fallbacks) {
    if (!embedderFallbackSelect) {
      return;
    }
    embedderFallbackSelect.innerHTML = "";
    fallbacks.forEach((name) => {
      const option = document.createElement("option");
      option.value = name;
      option.textContent = name;
      embedderFallbackSelect.appendChild(option);
    });
  }

  function manageEmbedderPolling(status) {
    if (state.embedder.pollTimer) {
      clearInterval(state.embedder.pollTimer);
      state.embedder.pollTimer = null;
    }
    if (status && status.state === "installing") {
      state.embedder.pollTimer = setInterval(() => {
        refreshEmbedderStatus({ triggerInstall: false });
      }, 1500);
    }
  }

  function updateEmbedderUI(status) {
    if (!embedderContainer) {
      return;
    }
    const stateName = status?.state || "unknown";
    const modelName = status?.model || "embeddinggemma";
    const progress = Number(status?.progress ?? 0);
    embedderContainer.hidden = false;
    embedderContainer.setAttribute("aria-busy", stateName === "installing" ? "true" : "false");

    if (embedderStatusText) {
      let message = "Checking Ollama…";
      if (stateName === "ready") {
        message = `Ready: ${modelName}`;
      } else if (stateName === "installing") {
        message = `Installing ${modelName}… ${Math.max(0, Math.min(100, progress))}%`;
      } else if (stateName === "missing") {
        message = `Model ${modelName} is not installed yet.`;
      } else if (stateName === "absent") {
        message = "Automatic installation is disabled in configuration.";
      } else if (stateName === "error") {
        message = status?.detail || status?.error || `Unable to prepare ${modelName}.`;
      }
      embedderStatusText.textContent = message;
    }

    if (embedderProgress && embedderProgressBar) {
      if (stateName === "installing") {
        const safe = Math.max(0, Math.min(100, progress || 0));
        embedderProgress.hidden = false;
        embedderProgress.setAttribute("aria-valuenow", String(safe));
        embedderProgressBar.style.width = `${safe}%`;
        embedderProgressBar.textContent = `${safe}%`;
      } else {
        embedderProgress.hidden = true;
        embedderProgress.setAttribute("aria-valuenow", String(progress || 0));
        embedderProgressBar.style.width = `${Math.max(0, Math.min(100, progress || 0))}%`;
        embedderProgressBar.textContent = "";
      }
    }

    if (embedderRetryBtn) {
      const allowRetry = stateName === "error" || stateName === "missing";
      embedderRetryBtn.hidden = !allowRetry;
      embedderRetryBtn.disabled = stateName === "installing";
    }

    if (embedderStartBtn) {
      const offline = status?.error === "ollama_offline" || status?.ollama?.alive === false;
      embedderStartBtn.hidden = !offline;
      embedderStartBtn.disabled = stateName === "installing";
    }

    const fallbackList = Array.isArray(status?.fallbacks)
      ? status.fallbacks.filter((name) => Boolean(name))
      : [];
    if (embedderFallbackGroup) {
      if (fallbackList.length && stateName === "error") {
        embedderFallbackGroup.hidden = false;
        populateFallbackOptions(fallbackList);
      } else {
        embedderFallbackGroup.hidden = true;
        if (embedderFallbackSelect) {
          embedderFallbackSelect.innerHTML = "";
        }
      }
    }

    if (embedderHelpText) {
      embedderHelpText.hidden = false;
    }
  }

  function handleEmbedderStatus(status) {
    state.embedder.status = status;
    updateEmbedderUI(status);
    manageEmbedderPolling(status);
    if (status && status.state === "ready" && state.embedder.pendingSearch) {
      const pending = state.embedder.pendingSearch;
      state.embedder.pendingSearch = null;
      updateStatus("Embedding ready. Running your query…", true);
      runSearch({ auto: pending.auto, skipEmbedCheck: true });
    }
  }

  async function refreshEmbedderStatus({ triggerInstall = false, model } = {}) {
    try {
      let response;
      if (triggerInstall) {
        const headers = { "Content-Type": "application/json" };
        const body = model ? JSON.stringify({ model }) : JSON.stringify({});
        response = await fetch("/api/embedder/ensure", {
          method: "POST",
          headers,
          body,
        });
      } else {
        response = await fetch("/api/embedder/status");
      }
      if (!response.ok) {
        throw new Error(`Embedder request failed: ${response.status}`);
      }
      const status = await response.json();
      handleEmbedderStatus(status);
      return status;
    } catch (error) {
      console.error(error);
      const fallbackStatus = {
        state: "error",
        error: "request_failed",
        detail: "Unable to reach embedder API.",
        model: (state.embedder.status && state.embedder.status.model) || "embeddinggemma",
        progress: 0,
        fallbacks: [],
      };
      handleEmbedderStatus(fallbackStatus);
      return null;
    }
  }

  async function ensureEmbedderReady({ auto = false } = {}) {
    let status = state.embedder.status;
    if (!status) {
      status = await refreshEmbedderStatus({ triggerInstall: false });
      if (!status) {
        updateStatus("Unable to determine embedding status.");
        return false;
      }
    }
    const modelName = status.model || "embeddinggemma";
    if (status.state === "ready") {
      return true;
    }
    if (status.state === "installing") {
      if (!state.embedder.pendingSearch) {
        state.embedder.pendingSearch = { auto };
      }
      updateStatus(`Installing ${modelName}… We'll run your query as soon as the model is ready.`, true);
      return false;
    }
    if (status.state === "error") {
      updateStatus("Embedding model unavailable. Resolve the issue above and retry.");
      return false;
    }
    if (status.state === "absent") {
      updateStatus('Auto-install disabled. Run "ollama pull embeddinggemma" manually and retry.');
      return false;
    }
    const ensured = await refreshEmbedderStatus({ triggerInstall: true });
    if (!ensured) {
      return false;
    }
    if (ensured.state === "ready") {
      return true;
    }
    if (ensured.state === "installing") {
      if (!state.embedder.pendingSearch) {
        state.embedder.pendingSearch = { auto };
      }
      updateStatus(`Installing ${ensured.model || modelName}… We'll run your query as soon as the model is ready.`, true);
      return false;
    }
    if (ensured.state === "error") {
      updateStatus("Embedding model unavailable. Resolve the issue above and retry.");
      return false;
    }
    return ensured.state === "ready";
  }

  async function initEmbedderStatus() {
    const status = await refreshEmbedderStatus({ triggerInstall: false });
    if (status && status.state === "missing" && status.auto_install) {
      await refreshEmbedderStatus({ triggerInstall: true });
    } else if (status && status.state === "unknown" && status.auto_install !== false) {
      await refreshEmbedderStatus({ triggerInstall: true });
    }
  }

  function escapeHTML(text) {
    return text
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/\"/g, "&quot;")
      .replace(/'/g, "&#39;");
  }

  function formatPlain(text) {
    return escapeHTML(text).replace(/\n/g, "<br>");
  }

  function formatInline(text) {
    let safe = escapeHTML(text);
    safe = safe.replace(/\[([^\]]+)\]\((https?:[^)]+)\)/g, '<a href="$2" target="_blank" rel="noopener noreferrer">$1</a>');
    safe = safe.replace(/(https?:\/\/[^\s)]+)/g, '<a href="$1" target="_blank" rel="noopener noreferrer">$1</a>');
    return safe;
  }

  function renderMarkdown(markdown) {
    const lines = markdown.split(/\r?\n/);
    const html = [];
    let inList = false;
    const closeList = () => {
      if (inList) {
        html.push("</ul>");
        inList = false;
      }
    };
    for (const line of lines) {
      if (line.startsWith("# ")) {
        closeList();
        html.push(`<h2>${formatInline(line.slice(2))}</h2>`);
      } else if (line.startsWith("## ")) {
        closeList();
        html.push(`<h3>${formatInline(line.slice(3))}</h3>`);
      } else if (line.startsWith("### ")) {
        closeList();
        html.push(`<h4>${formatInline(line.slice(4))}</h4>`);
      } else if (line.startsWith("- ")) {
        if (!inList) {
          html.push("<ul>");
          inList = true;
        }
        html.push(`<li>${formatInline(line.slice(2))}</li>`);
      } else if (!line.trim()) {
        closeList();
      } else {
        closeList();
        html.push(`<p>${formatInline(line)}</p>`);
      }
    }
    closeList();
    return html.join("\n");
  }

  function renderResults(results, payload = {}) {
    const answer = (payload.answer || "").trim();
    const sources = Array.isArray(payload.sources) ? payload.sources : [];
    const hasAnswer = Boolean(answer);
    const hasResults = Array.isArray(results) && results.length > 0;

    resultsEl.innerHTML = "";

    if (!hasAnswer && !hasResults) {
      resultsEl.innerHTML = '<p class="empty">No results yet. Trigger a crawl or wait for focused discovery.</p>';
      return;
    }

    const fragment = document.createDocumentFragment();

    if (hasAnswer) {
      const article = document.createElement("article");
      article.className = "result answer";

      const heading = document.createElement("h2");
      heading.textContent = "AI Summary";
      article.appendChild(heading);

      const body = document.createElement("div");
      body.className = "answer-body";
      body.innerHTML = renderMarkdown(answer);
      article.appendChild(body);

      if (sources.length) {
        const sourcesHeading = document.createElement("h3");
        sourcesHeading.textContent = "Sources";
        article.appendChild(sourcesHeading);

        const list = document.createElement("ol");
        list.className = "sources";
        sources.forEach((source, index) => {
          const item = document.createElement("li");
          const title = source.title || source.url || `Source ${index + 1}`;
          if (source.url) {
            const link = document.createElement("a");
            link.href = source.url;
            link.target = "_blank";
            link.rel = "noopener noreferrer";
            link.textContent = title;
            item.appendChild(link);
          } else {
            item.textContent = title;
          }
          const scoreValue = Number(
            source.similarity ?? source.score ?? 0
          );
          if (!Number.isNaN(scoreValue) && scoreValue > 0) {
            const score = document.createElement("span");
            score.className = "score";
            score.textContent = ` (${scoreValue.toFixed(3)})`;
            item.appendChild(score);
          }
          list.appendChild(item);
        });
        article.appendChild(list);
      }

      fragment.appendChild(article);
    }

    if (hasResults) {
      results.forEach((result) => {
        const article = document.createElement("article");
        article.className = "result";

        const heading = document.createElement("h2");
        const link = document.createElement("a");
        link.href = result.url;
        link.textContent = result.title || result.url;
        link.target = "_blank";
        link.rel = "noopener noreferrer";
        heading.appendChild(link);
        article.appendChild(heading);

        const url = document.createElement("p");
        url.className = "url";
        url.textContent = result.url || "";
        article.appendChild(url);

        if (result.lang) {
          const lang = document.createElement("p");
          lang.className = "lang";
          lang.textContent = `Language: ${result.lang}`;
          article.appendChild(lang);
        }

        if (result.snippet) {
          const snippet = document.createElement("p");
          snippet.className = "snippet";
          snippet.innerHTML = result.snippet;
          article.appendChild(snippet);
        }

        const score = document.createElement("p");
        score.className = "score";
        score.textContent = `Score: ${Number(result.score || 0).toFixed(3)}`;
        article.appendChild(score);

        fragment.appendChild(article);
      });
    } else if (hasAnswer) {
      const note = document.createElement("p");
      note.className = "empty";
      note.textContent = "No supporting documents yet. Trigger a crawl to enrich the index.";
      fragment.appendChild(note);
    }

    resultsEl.appendChild(fragment);
  }

  function handleSearchError(status, payload) {
    const code = payload && payload.code;
    if (code === "embedding_unavailable") {
      const detail = payload?.detail ||
        "Semantic search requires a local embedding model.";
      const action = payload?.action ? `<pre><code>${escapeHTML(payload.action)}</code></pre>` : "";
      resultsEl.innerHTML = `
        <article class="result">
          <h2>Embedding model required</h2>
          <p>${escapeHTML(detail)}</p>
          ${action}
        </article>
      `;
      updateStatus("Install the embedding model to enable semantic search.");
      return;
    }
    const message =
      (payload && (payload.detail || payload.error)) ||
      `Search failed (${status}).`;
    resultsEl.innerHTML = `<p class="empty">${escapeHTML(message)}</p>`;
    updateStatus(`Search failed (${status}).`);
  }

  function renderFocusedLog(lines, message) {
    focusedLog.textContent = lines.length ? lines.join("\n") : "Waiting for crawler output...";
    focusedMessage.textContent = message;
  }

  function stopSearchPolling() {
    if (state.searchJobTimer) {
      clearInterval(state.searchJobTimer);
      state.searchJobTimer = null;
    }
    if (state.indexTimer) {
      clearInterval(state.indexTimer);
      state.indexTimer = null;
    }
    state.searchJobId = null;
    focusedSection.hidden = true;
    focusedSection.setAttribute("aria-busy", "false");
    renderFocusedLog([], "Focused crawl idle.");
  }

  function startSearchPolling(jobId, baseline) {
    state.searchJobId = jobId;
    state.baselineIndexTime = baseline || 0;
    state.latestIndexTime = baseline || 0;
    state.autoRefresh = true;
    focusedSection.hidden = false;
    focusedSection.setAttribute("aria-busy", "true");
    renderFocusedLog([], "Focused crawl queued…");
    pollSearchJob();
    if (state.searchJobTimer) {
      clearInterval(state.searchJobTimer);
    }
    if (state.indexTimer) {
      clearInterval(state.indexTimer);
    }
    state.searchJobTimer = setInterval(pollSearchJob, 3000);
    state.indexTimer = setInterval(checkIndexUpdate, 4000);
  }

  async function pollSearchJob() {
    if (!state.searchJobId) {
      return;
    }
    try {
      const response = await fetch(`/api/jobs/${state.searchJobId}/status`);
      if (!response.ok) {
        throw new Error(`Job status failed: ${response.status}`);
      }
      const payload = await response.json();
      const tail = Array.isArray(payload.logs_tail) ? payload.logs_tail.slice(-3) : [];
      const stateText = payload.state === "running"
        ? "Focused crawl running. New results will appear automatically."
        : payload.state === "done"
        ? "Focused crawl finished. Refreshing results…"
        : payload.state === "error"
        ? "Focused crawl failed. Check logs."
        : "Focused crawl queued…";
      renderFocusedLog(tail, stateText);
      if (payload.state === "error") {
        state.autoRefresh = false;
        focusedSection.setAttribute("aria-busy", "false");
      }
    } catch (error) {
      console.error(error);
      renderFocusedLog(["Unable to read focused crawl log."], "Status unavailable.");
    }
  }

  async function checkIndexUpdate() {
    try {
      const response = await fetch("/api/focused/last_index_time");
      if (!response.ok) {
        throw new Error(`Index status failed: ${response.status}`);
      }
      const payload = await response.json();
      const value = Number(payload.last_index_time || 0);
      state.latestIndexTime = Math.max(state.latestIndexTime, value);
      if (state.autoRefresh && value > state.baselineIndexTime) {
        state.autoRefresh = false;
        await runSearch({ auto: true });
      }
    } catch (error) {
      console.error(error);
    }
  }

  function buildParams(auto) {
    if (auto && state.lastParams) {
      return new URLSearchParams(state.lastParams);
    }
    const params = new URLSearchParams();
    params.set("q", queryInput.value.trim());
    params.set("llm", llmToggle.checked ? "on" : "off");
    if (llmModelSelect.value) {
      params.set("model", llmModelSelect.value);
    }
    state.lastParams = params.toString();
    return params;
  }

  async function runSearch({ auto = false, skipEmbedCheck = false } = {}) {
    const query = auto ? state.lastQuery : queryInput.value.trim();
    if (!query) {
      updateStatus("Enter a query to search your local index.");
      renderResults([], {});
      stopSearchPolling();
      return;
    }
    const params = buildParams(auto);
    params.set("q", query);
    state.lastQuery = query;

    if (!skipEmbedCheck) {
      const ready = await ensureEmbedderReady({ auto });
      if (!ready) {
        return;
      }
    }

    updateStatus(auto ? "Refreshing results…" : "Searching index…", true);
    try {
      const response = await fetch(`/api/search?${params.toString()}`);
      let payload = null;
      try {
        payload = await response.json();
      } catch (parseError) {
        payload = null;
      }
      if (!response.ok) {
        handleSearchError(response.status, payload || {});
        stopSearchPolling();
        return;
      }
      const data = payload || {};
      const results = Array.isArray(data.results) ? data.results : [];
      renderResults(results, data);
      if (data.status === "focused_crawl_running" && data.job_id) {
        updateStatus("Focused crawl running. Waiting for new documents…", true);
        startSearchPolling(data.job_id, Number(data.last_index_time || 0));
      } else {
        stopSearchPolling();
        const count = results.length;
        const hasAnswer = Boolean((data.answer || "").trim());
        if (!count && !hasAnswer) {
          updateStatus("No results found. Try a different query or wait for new data.");
        } else {
          updateStatus(`Found ${count} result${count === 1 ? "" : "s"}.`);
        }
      }
    } catch (error) {
      console.error(error);
      updateStatus("Search failed. Check console logs for details.");
      stopSearchPolling();
    }
  }

  async function fetchLLMStatus() {
    try {
      const response = await fetch("/api/llm/status");
      if (!response.ok) {
        throw new Error(`Status request failed: ${response.status}`);
      }
      const status = await response.json();
      applyLLMStatus(status);
    } catch (error) {
      console.error(error);
      llmStatusEl.textContent = "Ollama: Unable to determine status";
      llmInstructions.hidden = false;
      llmModelSelect.disabled = true;
      llmToggle.disabled = true;
      setAssistAvailability(false);
    }
  }

  async function fetchLLMModels() {
    try {
      const response = await fetch("/api/llm/models");
      if (!response.ok) {
        throw new Error(`Model request failed: ${response.status}`);
      }
      const payload = await response.json();
      populateModelSelect(payload.models || []);
    } catch (error) {
      console.error(error);
      populateModelSelect([]);
    }
  }

  function setAssistAvailability(ready) {
    [chatInput, chatSend, researchQuery, researchBudget].forEach((el) => {
      if (el) {
        el.disabled = !ready;
      }
    });
    researchForm.querySelectorAll("button").forEach((btn) => {
      btn.disabled = !ready;
    });
  }

  function populateModelSelect(models) {
    llmModelSelect.innerHTML = "";
    const availableModels = filterChatCapableModels(models);
    const hadRawModels = Array.isArray(models) && models.length > 0;
    const storedModel = localStorage.getItem(STORAGE_MODEL_KEY) || "";
    if (!availableModels.length) {
      const option = document.createElement("option");
      option.value = "";
      option.textContent = hadRawModels
        ? "No chat-capable models detected"
        : "No local models detected";
      llmModelSelect.appendChild(option);
      llmModelSelect.disabled = true;
      if (llmInstructionsText) {
        llmInstructionsText.textContent = hadRawModels
          ? 'Only embedding models were found. Pull a chat model (e.g. "ollama pull llama3.1:8b-instruct") to enable discovery:'
          : 'Ollama is running but no models were found. Pull one (e.g. "ollama pull llama3.1:8b-instruct") to enable discovery:';
      }
      llmInstructions.hidden = false;
      return;
    }
    if (llmInstructionsText) {
      llmInstructionsText.textContent = defaultInstructionsText;
    }
    llmInstructions.hidden = true;
    const placeholder = document.createElement("option");
    placeholder.value = "";
    placeholder.textContent = "Use Ollama default";
    llmModelSelect.appendChild(placeholder);

    let matched = false;
    availableModels.forEach((model) => {
      const option = document.createElement("option");
      option.value = model.name;
      option.textContent = model.name;
      if (model.name === storedModel) {
        option.selected = true;
        matched = true;
      }
      llmModelSelect.appendChild(option);
    });
    llmModelSelect.disabled = false;
    if (!matched && storedModel) {
      localStorage.removeItem(STORAGE_MODEL_KEY);
    }
  }

  function applyLLMStatus(status) {
    if (!status) {
      llmStatusEl.textContent = "Ollama: status unavailable";
      llmInstructions.hidden = false;
      llmModelSelect.disabled = true;
      llmToggle.disabled = true;
      setAssistAvailability(false);
      return;
    }
    const { installed, running, host } = status;
    if (!installed) {
      llmStatusEl.textContent = "Ollama not installed";
      llmInstructions.hidden = false;
      llmModelSelect.disabled = true;
      llmToggle.disabled = true;
      setAssistAvailability(false);
      return;
    }
    if (!running) {
      llmStatusEl.textContent = `Ollama installed on ${host}, but not running`;
      llmInstructions.hidden = false;
      llmModelSelect.disabled = true;
      llmToggle.disabled = true;
      setAssistAvailability(false);
      return;
    }
    llmStatusEl.textContent = `Ollama ready at ${host}`;
    llmInstructions.hidden = true;
    llmModelSelect.disabled = false;
    llmToggle.disabled = false;
    setAssistAvailability(true);
  }

  function appendChatMessage(role, content) {
    const wrapper = document.createElement("div");
    wrapper.className = `chat-message ${role}`;
    wrapper.innerHTML = `<p>${formatPlain(content)}</p>`;
    chatMessagesEl.appendChild(wrapper);
    chatMessagesEl.scrollTop = chatMessagesEl.scrollHeight;
    return wrapper;
  }

  function parseSSEChunk(chunk) {
    const lines = chunk.split("\n");
    const dataParts = [];
    for (const line of lines) {
      if (line.startsWith("data:")) {
        dataParts.push(line.slice(5).trimStart());
      }
    }
    return dataParts.join("");
  }

  function safeParseJSON(text) {
    try {
      return JSON.parse(text);
    } catch (error) {
      return null;
    }
  }

  async function sendChatMessage(text) {
    const question = text.trim();
    if (!question) {
      return;
    }
    const userMessage = { role: "user", content: question };
    state.chatMessages.push(userMessage);
    appendChatMessage("user", question);

    const requestMessages = state.chatMessages.slice();
    const assistantMessage = { role: "assistant", content: "" };
    state.chatMessages.push(assistantMessage);
    const assistantElement = appendChatMessage("assistant", "");

    chatForm.classList.add("busy");
    chatInput.value = "";
    chatInput.disabled = true;
    chatSend.disabled = true;

    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ messages: requestMessages, model: llmModelSelect.value || undefined }),
      });
      if (!response.ok || !response.body) {
        throw new Error(`Chat failed: ${response.status}`);
      }
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = "";
      const assistantIndex = state.chatMessages.length - 1;
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          break;
        }
        buffer += decoder.decode(value, { stream: true });
        let boundary = buffer.indexOf("\n\n");
        while (boundary !== -1) {
          const chunk = buffer.slice(0, boundary);
          buffer = buffer.slice(boundary + 2);
          const data = parseSSEChunk(chunk);
          const payload = safeParseJSON(data);
          if (payload && payload.type === "token") {
            state.chatMessages[assistantIndex].content += payload.content;
            assistantElement.innerHTML = `<p>${formatPlain(state.chatMessages[assistantIndex].content)}</p>`;
            chatMessagesEl.scrollTop = chatMessagesEl.scrollHeight;
          } else if (payload && payload.type === "error") {
            state.chatMessages[assistantIndex].content += `\n[Error: ${payload.content}]`;
            assistantElement.innerHTML = `<p>${formatPlain(state.chatMessages[assistantIndex].content)}</p>`;
          }
          boundary = buffer.indexOf("\n\n");
        }
      }
    } catch (error) {
      console.error(error);
      const assistantIndex = state.chatMessages.length - 1;
      state.chatMessages[assistantIndex].content = `Error: ${error.message}`;
      assistantElement.innerHTML = `<p>${formatPlain(state.chatMessages[assistantIndex].content)}</p>`;
    } finally {
      chatForm.classList.remove("busy");
      chatInput.disabled = false;
      chatSend.disabled = false;
      chatInput.focus();
    }
  }

  async function pollResearchJob() {
    if (!state.researchJobId) {
      return;
    }
    try {
      const response = await fetch(`/api/jobs/${state.researchJobId}/status`);
      if (!response.ok) {
        throw new Error(`Research status failed: ${response.status}`);
      }
      const payload = await response.json();
      const tail = Array.isArray(payload.logs_tail) ? payload.logs_tail.slice(-6) : [];
      researchLog.textContent = tail.length ? tail.join("\n") : "Waiting for job output...";
      if (payload.state === "done") {
        clearInterval(state.researchPollTimer);
        state.researchPollTimer = null;
        researchForm.classList.remove("busy");
        const result = payload.result || {};
        if (result.report_path) {
          await loadResearchReport(result.report_path);
        } else {
          researchReportContent.innerHTML = "<p>No report generated.</p>";
          researchReport.hidden = false;
        }
        state.researchJobId = null;
      } else if (payload.state === "error") {
        clearInterval(state.researchPollTimer);
        state.researchPollTimer = null;
        researchForm.classList.remove("busy");
        researchReport.hidden = true;
        if (payload.error) {
          researchLog.textContent += `\nError: ${payload.error}`;
        }
        state.researchJobId = null;
      }
    } catch (error) {
      researchLog.textContent = `Unable to read research status: ${error.message}`;
    }
  }

  async function loadResearchReport(path) {
    try {
      const response = await fetch(path);
      if (!response.ok) {
        throw new Error(`Report fetch failed: ${response.status}`);
      }
      const markdown = await response.text();
      researchReportContent.innerHTML = renderMarkdown(markdown);
      researchReportDownload.href = path;
      researchReport.hidden = false;
    } catch (error) {
      researchReportContent.innerHTML = `<p>${formatPlain(`Unable to load report: ${error.message}`)}</p>`;
      researchReportDownload.removeAttribute("href");
      researchReport.hidden = false;
    }
  }

  chatForm.addEventListener("submit", (event) => {
    event.preventDefault();
    sendChatMessage(chatInput.value);
  });

  researchForm.addEventListener("submit", async (event) => {
    event.preventDefault();
    if (!researchQuery.value.trim()) {
      return;
    }
    researchForm.classList.add("busy");
    researchReport.hidden = true;
    researchReportContent.innerHTML = "";
    researchReportDownload.removeAttribute("href");
    researchLog.textContent = "Submitting research job…";
    try {
      const response = await fetch("/api/research", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          query: researchQuery.value.trim(),
          model: llmModelSelect.value || undefined,
          budget: Number(researchBudget.value || 20),
        }),
      });
      const payload = await response.json();
      if (!response.ok) {
        throw new Error(payload.error || `HTTP ${response.status}`);
      }
      state.researchJobId = payload.job_id;
      pollResearchJob();
      if (state.researchPollTimer) {
        clearInterval(state.researchPollTimer);
      }
      state.researchPollTimer = setInterval(pollResearchJob, 3000);
    } catch (error) {
      researchLog.textContent = `Unable to start research: ${error.message}`;
      researchForm.classList.remove("busy");
    }
  });

  form.addEventListener("submit", (event) => {
    event.preventDefault();
    runSearch();
  });

  initEmbedderStatus();
  setTab("chat");
  fetchLLMStatus();
  fetchLLMModels();

  if (queryInput.value.trim()) {
    runSearch();
  }
</script>

  </body>
</html>
