crawler:
  user_agent: "SelfHostedSearchBot/0.1 (+local)"
  obey_robots: true
  download_delay_sec: 0.8
  concurrent_requests: 8
  concurrent_per_domain: 4
  depth_limit: 2
  per_domain_page_cap: 5
  use_js_fallback: true
  js_fallback_threshold_chars: 200
  frontier_db: "data/frontier.sqlite"
  robots_cache_dir: "data/robots_cache"
  max_pages_total: 50000

seeds:
  urls_file: "seeds/seeds.txt"
  domains_file: "seeds/domains.txt"
  sitemaps_file: "seeds/sitemaps.txt"

index:
  dir: "index"
  analyzer: "stemming"
  field_boosts:
    title: 2.0
    content: 1.0
  incremental: true

ui:
  host: "127.0.0.1"
  port: 5000
  page_len: 10
