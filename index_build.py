#!/usr/bin/env python3
"""
Index builder script for the self‑hosted search engine.

This script reads the newline‑delimited JSON file generated by the
crawler (`data/pages.jsonl`), cleans the data, and builds an inverted
index using the Whoosh library.  The resulting index is stored in
`index/` and can be queried by the search UI or CLI.

Run this script whenever you have new crawled data to refresh the
index.  You can safely run it multiple times; it will update existing
documents based on their URL.
"""
import json
from pathlib import Path
from whoosh import index
from whoosh.fields import Schema, ID, TEXT
from whoosh.analysis import StemmingAnalyzer

DATA_PATH = Path(__file__).resolve().parent / "data" / "pages.jsonl"
INDEX_DIR = Path(__file__).resolve().parent / "index"

def build_index():
    # Ensure index directory exists
    INDEX_DIR.mkdir(parents=True, exist_ok=True)

    # Define schema: URL is unique and stored; title is stored; content is indexed but not stored.
    schema = Schema(
        url=ID(stored=True, unique=True),
        title=TEXT(stored=True, analyzer=StemmingAnalyzer()),
        content=TEXT(stored=False, analyzer=StemmingAnalyzer()),
    )

    # Create or open the index
    if index.exists_in(INDEX_DIR):
        ix = index.open_dir(INDEX_DIR)
    else:
        ix = index.create_in(INDEX_DIR, schema)

    # Load documents
    if not DATA_PATH.exists():
        print(f"No pages found at {DATA_PATH}.  Have you run the crawler?")
        return

    total = 0
    with ix.writer(limitmb=256, procs=0, multisegment=True) as writer:
        with DATA_PATH.open("r", encoding="utf-8") as f:
            for line in f:
                try:
                    row = json.loads(line)
                except json.JSONDecodeError:
                    continue
                url = row.get("url")
                title = row.get("title") or ""
                text = row.get("text") or ""
                if not url:
                    continue
                writer.update_document(url=url, title=title, content=text)
                total += 1

    print(f"Indexed {total} documents into {INDEX_DIR}")

if __name__ == "__main__":
    build_index()